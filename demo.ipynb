{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dustin/anaconda3/envs/reid/lib/python3.8/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import NeptuneLogger\n",
    "from torch import nn\n",
    "from torchvision import transforms as T\n",
    "from typing import List\n",
    "from config import FT_NET_CFG, SHAPE_EMBEDDING_CFG\n",
    "from src.models.baseline import LitModule\n",
    "from src.datasets.get_loader import get_train_loader\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dustin/anaconda3/envs/reid/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "train_loader = get_train_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dustin/anaconda3/envs/reid/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "net = LitModule(shape_edge_index=torch.tensor(SHAPE_EMBEDDING_CFG.EDGE_INDEX),\n",
    "                shape_pose_n_features=SHAPE_EMBEDDING_CFG.POSE_N_FEATURES,\n",
    "                shape_n_hidden=SHAPE_EMBEDDING_CFG.N_HIDDEN,\n",
    "                shape_out_features=SHAPE_EMBEDDING_CFG.OUT_FEATURES,\n",
    "                shape_relation_layers=SHAPE_EMBEDDING_CFG.RELATION_LAYERS,\n",
    "                class_num=751,\n",
    "                r50_stride=FT_NET_CFG.R50_STRIDE,\n",
    "                r50_pretrained_weight=FT_NET_CFG.PRETRAINED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/dustin/anaconda3/envs/reid/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/dustin/anaconda3/envs/reid/lib/python3.8/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:411: UserWarning: A layer with UninitializedParameter was found. Thus, the total number of parameters detected may be inaccurate.\n",
      "  warning_cache.warn(\n",
      "\n",
      "  | Name              | Type           | Params\n",
      "-----------------------------------------------------\n",
      "0 | ft_net            | FTNet          | 25.6 M\n",
      "1 | shape_embedding   | ShapeEmbedding | 300 K \n",
      "2 | fusion            | FusionNet      | 2     \n",
      "3 | id_classification | Linear         | 769 K \n",
      "-----------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "25.6 M    Non-trainable params\n",
      "26.6 M    Total params\n",
      "106.511   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4627eaae7647fab1d0e648b6669655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dustin/anaconda3/envs/reid/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(accelerator='gpu', max_epochs=10)\n",
    "\n",
    "trainer.fit(model=net, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"/Users/jurgendn/Downloads/pose-02.jpg\")\n",
    "img = img.resize(size=(256, 128))\n",
    "img = T.ToTensor()(img)\n",
    "img = img.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = data[0]['pose_landmarks']\n",
    "pose = torch.FloatTensor(pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1024])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.forward(x_image=img, x_pose_features=pose.unsqueeze(0), edge_index=edge_index).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune_logger = NeptuneLogger(\n",
    "    project=\"jurgen/person-reid\",\n",
    "    api_key=\n",
    "    \"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vbmV3LXVpLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI2MWM3OWRkYi0yMTFlLTQzNjMtOGEzOS0yOGI0MjUxNmRkNjkifQ==\",\n",
    "    log_model_checkpoints=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/cuhk03/jsons/train.json', 'rb') as f:\n",
    "    img_list = json.load(f)\n",
    "\n",
    "import random  \n",
    "\n",
    "\n",
    "# def get_img_tensor(img_path):\n",
    "#     img = Image.open(img_path)\n",
    "#     img_tensor = transforms(img)\n",
    "#     return img_tensor\n",
    "\n",
    "\n",
    "# def get_pose_tensor(pose: List[List[float]]):\n",
    "#     return Tensor(pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getitem(img_list):\n",
    "    failed = []\n",
    "    for a_img in img_list:\n",
    "        a_img_path = a_img['img_path']\n",
    "        a_id = a_img['p_id']\n",
    "        a_orientation = a_img['orientation']\n",
    "        a_pose = a_img['pose_landmarks']\n",
    "\n",
    "        same_id, diff_id = [], []\n",
    "        for item in img_list:\n",
    "            if item['p_id'] == a_id:\n",
    "                same_id.append(item)\n",
    "            else:\n",
    "                diff_id.append(item)\n",
    "\n",
    "        same_id_diff_ori, diff_id_same_ori = [], []\n",
    "\n",
    "        if 0 <= a_orientation <= 9 or 63 <= a_orientation <= 71 or 27 <= a_orientation <= 45:\n",
    "            # anchor has back or front orientation\n",
    "            for item in same_id:\n",
    "                if 45 <= item[\"orientation\"] < 63 or 9 <= item[\"orientation\"] < 27:\n",
    "                    # found positive sample of sideway orientation\n",
    "                    same_id_diff_ori.append(item)\n",
    "            for item in diff_id:\n",
    "                if 0 <= item[\"orientation\"] <= 9 or 63 <= item[\"orientation\"] <= 71 or 27 <= item[\"orientation\"] <= 45:\n",
    "                    diff_id_same_ori.append(item)\n",
    "        else:\n",
    "            # anchor has sideway orientation\n",
    "            for item in same_id:\n",
    "                if 0 <= item[\"orientation\"] <= 9 or 63 <= item[\"orientation\"] <= 71 or 27 <= item[\"orientation\"] <= 45:\n",
    "                    # found positive sample of back orientation\n",
    "                    same_id_diff_ori.append(item)\n",
    "            for item in diff_id:\n",
    "                if 45 <= item[\"orientation\"] < 63 or 9 <= item[\"orientation\"] < 27:\n",
    "                    diff_id_same_ori.append(item)\n",
    "\n",
    "        # if len(diff_id_same_ori) == 0:\n",
    "        #     print(\n",
    "        #         a_img_path\n",
    "        #     )\n",
    "    \n",
    "        try:\n",
    "            p_img = random.choice(same_id_diff_ori)\n",
    "            n_img = random.choice(diff_id_same_ori)\n",
    "        except: \n",
    "            failed.append(a_id)\n",
    "\n",
    "    return [*set(failed)]\n",
    "        # p_img_path = p_img['img_path']\n",
    "        # p_pose = p_img['pose_landmarks']\n",
    "\n",
    "        \n",
    "        # n_img_path = n_img['img_path']\n",
    "        # n_pose = n_img['pose_landmarks']\n",
    "\n",
    "        # a_img_tensor = get_img_tensor(a_img_path)\n",
    "        # p_img_tensor = get_img_tensor(p_img_path)\n",
    "        # n_img_tensor = get_img_tensor(n_img_path)\n",
    "        # a_pose_tensor = get_pose_tensor(a_pose)\n",
    "        # p_pose_tensor = get_pose_tensor(p_pose)\n",
    "        # n_pose_tensor = get_pose_tensor(n_pose)\n",
    "         #(a_img_tensor, p_img_tensor, n_img_tensor), (a_pose_tensor, p_pose_tensor, n_pose_tensor), a_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = getitem(img_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/dustin/DATA/Research/2DReID/SMPLMarket/bounding_box_train/0007/0007_c1s6_028546_01.jpg',\n",
       " '/media/dustin/DATA/Research/2DReID/SMPLMarket/bounding_box_train/0007/0007_c1s6_028546_04.jpg',\n",
       " '/media/dustin/DATA/Research/2DReID/SMPLMarket/bounding_box_train/0007/0007_c2s3_071002_01.jpg',\n",
       " '/media/dustin/DATA/Research/2DReID/SMPLMarket/bounding_box_train/0007/0007_c2s3_071052_01.jpg',\n",
       " '/media/dustin/DATA/Research/2DReID/SMPLMarket/bounding_box_train/0007/0007_c3s3_077419_03.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "failed[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
